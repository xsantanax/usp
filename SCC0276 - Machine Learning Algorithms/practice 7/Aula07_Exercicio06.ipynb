{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Aula07-Exercicio06.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "LTpbHqrlBaNw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Aula 07 - Exercício 06\n",
        "## KNN e Métricas de avaliação\n",
        "### Alunos:\n",
        " - Felipe Yoshio Guskuma nºUSP 9292500\n",
        " - Rafael Rodrigues Santana nºUSP 7594375\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "OfZ4Vt27e2GK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    },
    {
      "metadata": {
        "id": "uTXmrvNrBkJB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "O dataset [\"Breast Cancer Wisconsin\"](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original) é um dataset que contém 699 instâncias, cada uma com 10 atributos númericos e 1 atributo correspondente a classe. A idéia do dataset é conseguir classificar um tumor como benigno ou maligno a partir de 10 variáveis descritivas. Foi adicionado um cabeçalho no arquivo original para facilitar seu manuseio.\n",
        "\n",
        "- Notas:\n",
        "\n",
        "  - **O dataset possui valores ausentes, representados por \"?\"**\n",
        "  - A primeira variável do dataset é o ID de cada paciente. Essa variável **NÃO** deve ser utilizada no classificador \n",
        "\n",
        "---\n",
        "\n",
        "- Carregue o dataset a partir do arquivo fornecido, substituindo os valores ausentes pela média dos valores daquela coluna. Utilize as classes `sklearn.impute.SimpleImputer` e a biblioteca `pandas`."
      ]
    },
    {
      "metadata": {
        "id": "T5VRbRDdUArr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "data = pd.read_csv(\"breast-cancer-wisconsin.data\", header = 0, usecols = range(1,11), na_values = '?')\n",
        "print(data)\n",
        "imp_mean = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
        "imp_mean.fit(data)\n",
        "datap = imp_mean.transform(data)\n",
        "print(datap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "09jpLsH0JeYH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "- Centralize e normalize os dados e separe 80% do conjunto para treino e 20% para testes. Faça uma divisão dos dados de maneira **estratificada**."
      ]
    },
    {
      "metadata": {
        "id": "rNb1jmocLWhG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler().fit(datap)\n",
        "X = scaler.transform(datap)\n",
        "Y = datap[:,9]\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size = 0.2, random_state = 1, stratify = Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XPr0CmMwD5-w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "- Faça classificação no conjunto de testes utilizando 4 classificadores KNN, com K=3 e 15 e p=1 e 2 (distância de Minkowski/Euclidiana). Para cada classificador, calcule e exiba a matriz de confusão bem como a acurácia do classificador. **Para calcular a acurácia, utilize APENAS a matriz de confusão.**"
      ]
    },
    {
      "metadata": {
        "id": "si5kXA-Oyj6O",
        "colab_type": "code",
        "outputId": "deea937f-81fa-480d-dac0-9f62398fe9f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "k = 3\n",
        "model = KNeighborsClassifier(n_neighbors=k, p = 1)\n",
        "# Train the model using the training sets\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "#Predict Output\n",
        "pred_y1= model.predict(test_x) \n",
        "\n",
        "confm = confusion_matrix(test_y, pred_y1)\n",
        "print(confm)\n",
        "acc = np.trace(confm) / np.sum(confm)\n",
        "print(acc)\n",
        "##############################################################################\n",
        "k = 15\n",
        "model = KNeighborsClassifier(n_neighbors=k, p = 2)\n",
        "# Train the model using the training sets\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "#Predict Output\n",
        "pred_y2= model.predict(test_x)\n",
        "\n",
        "confm = confusion_matrix(test_y, pred_y2)\n",
        "print(confm)\n",
        "acc = np.trace(confm) / np.sum(confm)\n",
        "print(acc)\n",
        "##############################################################################\n",
        "k = 3\n",
        "model = KNeighborsClassifier(n_neighbors=k, p = 1)\n",
        "# Train the model using the training sets\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "#Predict Output\n",
        "pred_y3= model.predict(test_x) \n",
        "\n",
        "confm = confusion_matrix(test_y, pred_y3)\n",
        "print(confm)\n",
        "acc = np.trace(confm) / np.sum(confm)\n",
        "print(acc)\n",
        "##############################################################################\n",
        "k = 15\n",
        "model = KNeighborsClassifier(n_neighbors=k, p = 2)\n",
        "# Train the model using the training sets\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "#Predict Output\n",
        "pred_y4= model.predict(test_x)\n",
        "confm = confusion_matrix(test_y, pred_y4)\n",
        "print(confm)\n",
        "acc = np.trace(confm) / np.sum(confm)\n",
        "print(acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[92  0]\n",
            " [ 1 47]]\n",
            "0.9928571428571429\n",
            "[[90  2]\n",
            " [ 1 47]]\n",
            "0.9785714285714285\n",
            "[[92  0]\n",
            " [ 1 47]]\n",
            "0.9928571428571429\n",
            "[[90  2]\n",
            " [ 1 47]]\n",
            "0.9785714285714285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I-xM0b4GM1Z4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Agora vamos analisar um problema de classificação não binário. Para isso, vamos utilizar o conjunto Iris. Repetindo os passos anteriores:\n",
        "- Carregue o conjunto Iris\n",
        "- Centralize e normalize os dados\n",
        "- Separe o conjunto, de maneira **NÃO** estratificada, em 50% treino e 50% teste (a ideia é que o classificador tenha um erro maior)\n",
        "- Utilize um classificador KNN com K=1 para predizer o conjunto de teste. Essa predição será utilizado posteriormente.\n"
      ]
    },
    {
      "metadata": {
        "id": "qR3G6nwVM2s4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "x, y = data = load_iris(return_X_y=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler().fit(x)\n",
        "X = scaler.transform(x)\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size = 0.5, random_state = 1, stratify = None)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "k = 1\n",
        "model = KNeighborsClassifier(n_neighbors=k, p = 1)\n",
        "# Train the model using the training sets\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "#Predict Output\n",
        "pred_y1= model.predict(test_x) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3mdi9Mf0QGq8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "- Mostre a matriz de confusão do conjunto de teste e em seguida, para cada variável do conjunto, mostre sua matriz de confusão binária.\n",
        "  - Dica: Pesquise sobre o método `numpy.delete`"
      ]
    },
    {
      "metadata": {
        "id": "M-3uPd6MQTWT",
        "colab_type": "code",
        "outputId": "fe260e3b-50af-480a-ab3b-712ee93c7c4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "cell_type": "code",
      "source": [
        "confm = confusion_matrix(test_y, pred_y1)\n",
        "print(confm)\n",
        "acc = np.trace(confm) / np.sum(confm)\n",
        "print(acc)\n",
        "\n",
        "#######################################################\n",
        "m = np.zeros((2,2))\n",
        "k = len(confm)\n",
        "for i in range(k):\n",
        "  m[0][0] = confm[i][i]\n",
        "  m[0][1] = np.sum(confm[i,:]) - confm[i][i]\n",
        "  m[1][0] = np.sum(confm[:,i]) - confm[i][i]\n",
        "  m[1][1] = np.sum(confm)-m[1][0]-m[0][1]-m[0][0]\n",
        "  print(\"classe\", i )\n",
        "  print(m)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[24  0  0]\n",
            " [ 0 24  0]\n",
            " [ 0  4 23]]\n",
            "0.9466666666666667\n",
            "classe 0\n",
            "[[24.  0.]\n",
            " [ 0. 51.]]\n",
            "classe 1\n",
            "[[24.  0.]\n",
            " [ 4. 47.]]\n",
            "classe 2\n",
            "[[23.  4.]\n",
            " [ 0. 48.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RZT3vF7uR3VJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "- Utilizando as matrizes de confusão binárias calculadas acima, calcule o **Recall** e **Precisão** de cada variável do conjunto.\n",
        "  - Dica 1: Lembre-se que ao calcular a matriz de confusão binária para cada classe, obtemos os valores VP, FP, FN e VN.\n",
        "  - Dica 2: Lembre-se que Recall é calculado por $\\frac{VP}{VP+FN}$ e Precisão por  $\\frac{VP}{VP+FP}$."
      ]
    },
    {
      "metadata": {
        "id": "guT6-yJ-S6uI",
        "colab_type": "code",
        "outputId": "30ee9a2e-d941-4a2d-a3fd-5d6a48c78f2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(k):\n",
        "  m[0][0] = confm[i][i]\n",
        "  m[0][1] = np.sum(confm[i,:]) - confm[i][i]\n",
        "  m[1][0] = np.sum(confm[:,i]) - confm[i][i]\n",
        "  m[1][1] = np.sum(confm)-m[1][0]-m[0][1]-m[0][0]\n",
        "  \n",
        "  \n",
        "  print(\"classe\", i )\n",
        "  recall = m[0][0]/(m[0][0]+m[1][0]) \n",
        "  print(recall)\n",
        "  precisao = m[0][0]/(m[0][0]+m[0][1]) \n",
        "  print(precisao)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classe 0\n",
            "1.0\n",
            "1.0\n",
            "classe 1\n",
            "0.8571428571428571\n",
            "1.0\n",
            "classe 2\n",
            "1.0\n",
            "0.8518518518518519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "APzuX9F9HNGB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Considere o conjunto de dados abaixo, onde são representados um conjunto de $n$ pontos que podem ser classificados em duas classes: verde ou azul. **Todo** o conjunto pode ser visto na imagem abaixo. O ponto preto $q$ é um ponto de consulta, cuja classe é desconhecida. Suponha que foi usado um classificador do tipo KNN com distância euclidiana para classificar esse ponto.\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1e7oUOHOwyFZ8R1Xy0FPUJ8n_M0YGB2_d)\n",
        "\n",
        "\n",
        "- Qual a saída desse classificador para K=3?"
      ]
    },
    {
      "metadata": {
        "id": "7hcbOzE_KHQC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**O ponto q será classificado como azul, já que os três pontos mais próximos são azuis**"
      ]
    },
    {
      "metadata": {
        "id": "mMQTSRbO4Mj3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "XeDZ96YeJut7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "- E para K=9?"
      ]
    },
    {
      "metadata": {
        "id": "pS8FZKxtKH0F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**O ponto q será classificado como verde, já que entre os nove pontos mais próximos seis são verdes e apenas três são azuis**"
      ]
    },
    {
      "metadata": {
        "id": "llhVvRuqJ053",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        " - E para o caso extremo de K=$n$? A posição de $q$ no espaço interfere nesse resultado? Justifique."
      ]
    },
    {
      "metadata": {
        "id": "BHP1oCXHKIMx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**No caso extremo será classificado como verde, pois a maioria dos pontos são verdes. A posição do ponto não interfere, pois a análise engloba todos os pontos.**"
      ]
    }
  ]
}