{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Funcionamento PolynomialFeatures.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"pe-lLjBpQ8xy","colab_type":"text"},"cell_type":"markdown","source":["# PolynomialFeatures\n","\n","Como a documentação do sklearn não estava muito clara, achei melhor esclarecer como funciona a regressão polinomial.\n","\n","Suponha que temos uma base de dados $D$ que possui variáveis de nome $A, B$ e valor de função $T$. Uma observação dessas variáveis é dada por $(a_0, b_0)$, com valor $t_0$. \n","\n","\n","* Uma aproximação linear de $t_0$ (suponha que os valores  $\\beta_i$ foram encontrados utilizando algum algoritmo como mínimos quadrados) pode ser dada por:\n","\n","  $t^{(1)}_0=f^{(1)}(a_0, b_0)= \\beta^{(1)}_0 + \\beta^{(1)}_1 a_0 + \\beta^{(1)}_2 b_0 $\n","\n","* Uma aproximação quadrática (polinômio de segundo grau) da função pode ser vista da forma:\n","\n","  $t^{(2)}_0=f^{(2)}(a_0, b_0)= \\beta^{(2)}_0 + \\beta^{(2)}_1 a_0 + \\beta^{(2)}_2 b_0 + \\beta^{(2)}_4 a_0^2 + \\beta^{(2)}_5 b_0^2 + \\beta^{(2)}_7 a_0 b_0$\n","\n","* Note que podemos encarar \"aproximar via função quadrática\" como \"aproximar via função linear\" se considerarmos $a_0^2$, $b_0^2$ e $a_0b_0$ como novas variáveis, $c_0, d_0$ e $e_0$ no problema:\n","\n","  $t^{(3)}_0=f^{(3)}(a_0, b_0, c_0, d_0, e_0)= \\beta^{(3)}_0 + \\beta^{(3)}_1 a_0 + \\beta^{(3)}_2 b_0 + \\beta^{(3)}_3 c_0 + \\beta^{(3)}_4 d_0 + \\beta^{(3)}_5 e_0$\n","\n","* Basta que realizemos a transformação de $(a, b)$ para $(a, b, c, d, e)$, com $c=a^2, d=b^2$ e $e=ab$.\n","\n","\n","---\n","\n","\n","Felizmente a classe **PolynomialFeatures** é bastante útil nesse momento, pois ela nos permite realizar essa transformação facilmente, de forma que consigamos utilizar a mesma sintaxe utilizado anteriormente para adaptar nosso modelo linear.\n","\n","Basta inicializar um polinômio e transformar o conjunto de dados, por exemplo:\n","\n","```python\n","p = PolynomialFeatures(degree=grau)\n","X_Transf = p.fit_transform(X)\n","```\n","\n","E agora ao invés de adaptar nosso modelo linear ao conjunto X, adaptamos ao conjunto X_Transf.\n"]},{"metadata":{"id":"iI0gl-e6OWML","colab_type":"code","outputId":"d8a95204-1c2a-4f71-fa20-c501abd50fda","executionInfo":{"status":"ok","timestamp":1553146309668,"user_tz":180,"elapsed":623,"user":{"displayName":"Rafael Santana","photoUrl":"https://lh6.googleusercontent.com/-jb2MFAf8gE8/AAAAAAAAAAI/AAAAAAAAE2I/wYi3IrucePU/s64/photo.jpg","userId":"12724017190090937430"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"cell_type":"code","source":["from sklearn.preprocessing import PolynomialFeatures\n","import numpy as np\n","\n","#3 observações de 2 variáveis\n","\n","x = np.array([[1, 2],\n","              [3, 4],\n","              [5, 6]])\n","\n","# Utilizando um polinomio de grau 3\n","p = PolynomialFeatures(degree=2)\n","\n","X_Transf = p.fit_transform(x)\n","print(p.get_feature_names())\n","print(X_Transf)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["['1', 'x0', 'x1', 'x0^2', 'x0 x1', 'x1^2']\n","[[ 1.  1.  2.  1.  2.  4.]\n"," [ 1.  3.  4.  9. 12. 16.]\n"," [ 1.  5.  6. 25. 30. 36.]]\n"],"name":"stdout"}]}]}