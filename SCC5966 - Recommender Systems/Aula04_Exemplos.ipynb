{"cells":[{"cell_type":"markdown","metadata":{"id":"OC4JN4hrpk7n"},"source":["# Aula 04 - Exemplos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwBeOhCaERjC"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"W-GyAVDdpk7q"},"source":["## Fazendo download da base"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18832,"status":"ok","timestamp":1694896345059,"user":{"displayName":"Rafael Santana","userId":"12724017190090937430"},"user_tz":180},"id":"OD_v_w7Xl4aO","outputId":"d46be670-7ba7-47c6-e8aa-ae56a3076dfe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=1f4fdeacdf36430f9cc2b2ff955cafac960906fb5aafb0bfd4562d6d3da8b497\n","  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n","\n","Saved under ml-20m-compact.tar.gz\n","dataset/\n","dataset/tags_sample.csv\n","dataset/._.DS_Store\n","dataset/.DS_Store\n","dataset/movies_sample.csv\n","dataset/._genome-tags.csv\n","dataset/genome-tags.csv\n","dataset/._ml-youtube.csv\n","dataset/ml-youtube.csv\n","dataset/._genome-scores.csv\n","dataset/genome-scores.csv\n","dataset/ratings_sample.csv\n"]}],"source":["!pip install wget\n","!python3 -m wget https://github.com/mmanzato/MBABigData/raw/master/ml-20m-compact.tar.gz\n","!tar -xvzf ml-20m-compact.tar.gz"]},{"cell_type":"markdown","metadata":{"id":"S_bo-yZVngYP"},"source":["## Ler e preparar dados (vide notebooks anteriores)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFc5AN6-mBWT"},"outputs":[],"source":["movies = pd.read_csv('./dataset/movies_sample.csv')\n","ratings = pd.read_csv('./dataset/ratings_sample.csv')\n","df = ratings[['userId', 'movieId', 'rating']]\n","df = df.merge(movies[['movieId', 'title']])\n","map_users = {user: idx for idx, user in enumerate(df.userId.unique())}\n","map_items = {item: idx for idx, item in enumerate(df.movieId.unique())}\n","df['userId'] = df['userId'].map(map_users)\n","df['movieId'] = df['movieId'].map(map_items)\n","\n","map_title = {}\n","for _, row in df.iterrows():\n","    map_title[row.movieId] = row.title"]},{"cell_type":"markdown","metadata":{"id":"PG2-igcjGgzs"},"source":["## Avaliação no cenário de predição de notas (rating prediction)"]},{"cell_type":"markdown","metadata":{"id":"RUne6nOFpk7t"},"source":["### Cross-Validation"]},{"cell_type":"code","source":["# install caserec\n","import sys\n","!{sys.executable} -m pip install caserecommender"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vAMcdaFpstp1","executionInfo":{"status":"ok","timestamp":1694896450889,"user_tz":180,"elapsed":4761,"user":{"displayName":"Rafael Santana","userId":"12724017190090937430"}},"outputId":"83534420-8b80-43ff-d57c-a9a3df93fe02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: caserecommender in /usr/local/lib/python3.10/dist-packages (1.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from caserecommender) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from caserecommender) (1.11.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from caserecommender) (1.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from caserecommender) (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->caserecommender) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->caserecommender) (2023.3.post1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->caserecommender) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->caserecommender) (3.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->caserecommender) (1.16.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59383,"status":"ok","timestamp":1694896510271,"user":{"displayName":"Rafael Santana","userId":"12724017190090937430"},"user_tz":180},"id":"L1EoGufqFHJp","outputId":"f66a535f-68fa-408b-d634-85537795a375"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Case Recommender: Cross Validation]\n","\n","Database:: ratings.dat \n","Recommender Algorithm:: ItemKNN Algorithm | K Folds: 5\n","\n","Eval:: MAE: 0.801819 RMSE: 1.064265 \n","Eval:: MAE: 0.800534 RMSE: 1.064435 \n","Eval:: MAE: 0.796414 RMSE: 1.060053 \n","Eval:: MAE: 0.803863 RMSE: 1.068898 \n","Eval:: MAE: 0.793535 RMSE: 1.056095 \n","Mean:: MAE: 0.799233 RMSE: 1.062749 \n","STD:: MAE: 0.003748 RMSE: 0.004347 \n"]}],"source":["from caserec.utils.cross_validation import CrossValidation\n","from caserec.recommenders.rating_prediction.itemknn import ItemKNN\n","\n","df.to_csv('ratings.dat', index=False, header=False, sep='\\t')\n","\n","recommender = ItemKNN()\n","CrossValidation(input_file='ratings.dat', recommender=recommender, dir_folds='./', header=1, k_folds=5).compute()"]},{"cell_type":"markdown","metadata":{"id":"l0_3LF8Jpk7t"},"source":["### Hold-Out"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19262,"status":"ok","timestamp":1694896529529,"user":{"displayName":"Rafael Santana","userId":"12724017190090937430"},"user_tz":180},"id":"gnQKrVXnDurV","outputId":"f1c654e1-b66e-4b63-9884-5ac235f44eaf"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Case Recommender: Rating Prediction > ItemKNN Algorithm]\n","\n","train data:: 11090 users and 403 items (152496 interactions) | sparsity:: 96.59%\n","test data:: 10503 users and 340 items (38125 interactions) | sparsity:: 98.93%\n","\n","training_time:: 13.652960 sec\n","prediction_time:: 2.255743 sec\n","Eval:: MAE: 0.665964 RMSE: 0.876739 \n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","train, test = train_test_split(df, test_size=.2, random_state=2)\n","train.to_csv('train.dat', index=False, header=False, sep='\\t')\n","test.to_csv('test.dat', index=False, header=False, sep='\\t')\n","\n","\n","ItemKNN('train.dat', 'test.dat', 'rp_iknn.dat', as_similar_first=True).compute()"]},{"cell_type":"markdown","metadata":{"id":"J8_jOiYlpk7u"},"source":["### Explorando as predições"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1694896529530,"user":{"displayName":"Rafael Santana","userId":"12724017190090937430"},"user_tz":180},"id":"dqOhsX0XEIG_","outputId":"3987ba9a-223f-438f-a11e-6d40b6076b13"},"outputs":[{"output_type":"stream","name":"stdout","text":["[4.26384, 3.824934]\n"]}],"source":["preds = pd.read_csv('./rp_iknn.dat', sep='\\t', names=['userId', 'movieId', 'rating'])\n","preds_user = preds.loc[(preds.userId==0), 'rating'].tolist()\n","print(preds_user)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1694896529530,"user":{"displayName":"Rafael Santana","userId":"12724017190090937430"},"user_tz":180},"id":"fG8zLJsFFVN9","outputId":"bf80918a-53ea-4145-8da5-25c167549d5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[5.0, 5.0]\n"]}],"source":["ratings_user = test.loc[(test.userId==0), 'rating'].tolist()\n","print(ratings_user)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTnf1nHjpk7u","executionInfo":{"status":"ok","timestamp":1694896529530,"user_tz":180,"elapsed":3,"user":{"displayName":"Rafael Santana","userId":"12724017190090937430"}},"outputId":"009c9ef9-61a4-4251-d962-b809f39774e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.9804875445297611\n"]}],"source":["from math import sqrt\n","\n","def rmse_user(preds, ratings):\n","    if len(preds) != len(ratings):\n","        return -1\n","    sum = 0\n","    for i in range(len(preds)):\n","        sum += pow(preds[i]-ratings[i], 2)\n","    return sqrt(sum/len(preds))\n","\n","print(rmse_user(preds_user, ratings_user))"]},{"cell_type":"markdown","metadata":{"id":"lch6FzLoGF4F"},"source":["## Avaliação no cenário de recomendação de itens (item recommendation)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":157968,"status":"ok","timestamp":1694896699542,"user":{"displayName":"Rafael Santana","userId":"12724017190090937430"},"user_tz":180},"id":"hTgDDYUlGJTc","outputId":"a0fd4750-5475-42c8-cc73-6535af0503e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Case Recommender: Item Recommendation > BPRMF]\n","\n","train data:: 11090 users and 403 items (152496 interactions) | sparsity:: 96.59%\n","test data:: 10503 users and 340 items (38125 interactions) | sparsity:: 98.93%\n","\n","training_time:: 150.159013 sec\n","prediction_time:: 2.853613 sec\n","\n","\n","Eval:: PREC@1: 0.371418 PREC@3: 0.272779 PREC@5: 0.232257 PREC@10: 0.175645 RECALL@1: 0.116727 RECALL@3: 0.246369 RECALL@5: 0.342788 RECALL@10: 0.508531 MAP@1: 0.371418 MAP@3: 0.463098 MAP@5: 0.469203 MAP@10: 0.445974 NDCG@1: 0.371418 NDCG@3: 0.550143 NDCG@5: 0.571434 NDCG@10: 0.572217 \n"]}],"source":["from caserec.recommenders.item_recommendation.bprmf import BprMF\n","\n","BprMF('train.dat', 'test.dat', 'ir_bprmf.dat', factors=3).compute()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67786,"status":"ok","timestamp":1694896767326,"user":{"displayName":"Rafael Santana","userId":"12724017190090937430"},"user_tz":180},"id":"y3BFGK-6Hcg9","outputId":"6dabca6a-8db3-423c-8bcb-b6de2536e393"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Case Recommender: Item Recommendation > ItemKNN Algorithm]\n","\n","train data:: 11090 users and 403 items (152496 interactions) | sparsity:: 96.59%\n","test data:: 10503 users and 340 items (38125 interactions) | sparsity:: 98.93%\n","\n","training_time:: 1.303467 sec\n","prediction_time:: 60.527441 sec\n","\n","\n","Eval:: PREC@1: 0.419023 PREC@3: 0.307975 PREC@5: 0.254384 PREC@10: 0.187261 RECALL@1: 0.134438 RECALL@3: 0.281617 RECALL@5: 0.378529 RECALL@10: 0.546924 MAP@1: 0.419023 MAP@3: 0.513599 MAP@5: 0.516788 MAP@10: 0.487732 NDCG@1: 0.419023 NDCG@3: 0.603503 NDCG@5: 0.620406 NDCG@10: 0.613585 \n"]}],"source":["from caserec.recommenders.item_recommendation.itemknn import ItemKNN\n","\n","ItemKNN('train.dat', 'test.dat', 'ir_itemknn.dat').compute()"]},{"cell_type":"markdown","metadata":{"id":"uHqMWXvupk7v"},"source":["### Explorando as recomendações"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g5ChyEdipk7v","executionInfo":{"status":"ok","timestamp":1694896767326,"user_tz":180,"elapsed":4,"user":{"displayName":"Rafael Santana","userId":"12724017190090937430"}},"outputId":"f9585c78-8f87-419d-9f1a-3f34e88544b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["[12, 21, 17, 20, 10, 22, 28, 8, 43, 61]\n"]}],"source":["recs = pd.read_csv('./ir_bprmf.dat', sep='\\t', names=['userId', 'movieId', 'score'])\n","recs_user = recs.loc[(recs.userId==1), 'movieId'].tolist()\n","print(recs_user)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gsG6gGY3pk7v","executionInfo":{"status":"ok","timestamp":1694896767327,"user_tz":180,"elapsed":4,"user":{"displayName":"Rafael Santana","userId":"12724017190090937430"}},"outputId":"2fced64b-7d47-4ee2-f519-7392ce7aee5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[6, 106, 21, 30, 12]\n"]}],"source":["ground_truth = test.loc[(test.userId==1), 'movieId'].tolist()\n","print(ground_truth)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cEleZN7qpk7v","executionInfo":{"status":"ok","timestamp":1694896767327,"user_tz":180,"elapsed":3,"user":{"displayName":"Rafael Santana","userId":"12724017190090937430"}},"outputId":"1464782f-f049-44ed-9fb5-71dc06b4f139"},"outputs":[{"output_type":"stream","name":"stdout","text":["Precisão: 0.2\n","Revocação: 0.4\n"]}],"source":["intersec = list(set(recs_user) & set(ground_truth))\n","print('Precisão: ' + str(len(intersec)/len(recs_user)))\n","print('Revocação: ' + str(len(intersec)/len(ground_truth)))"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}